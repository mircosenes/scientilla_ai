{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from adapters import AutoAdapterModel\n",
    "import torch.nn.functional as F\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to DB and load adapter for the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 4 files: 100%|██████████| 4/4 [00:00<00:00, 27103.74it/s]\n",
      "There are adapters available but none are activated for the forward pass.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'query'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = psycopg2.connect(\n",
    "    dbname=\"scientilla\",\n",
    "    user=\"postgres\",\n",
    "    password=\"pwd\",\n",
    "    host=\"localhost\",\n",
    "    port=5444,\n",
    ")\n",
    "cur = conn.cursor()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/specter2_base\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "doc_model = AutoAdapterModel.from_pretrained(\"allenai/specter2_base\")\n",
    "\n",
    "doc_model.load_adapter(\n",
    "    \"allenai/specter2_adhoc_query\",\n",
    "    source=\"hf\",\n",
    "    load_as=\"query\",\n",
    "    set_active=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def embed_input(model, text_batch):\n",
    "    \"\"\"Calculate the embeddings for a batch of texts.\n",
    "    Args:\n",
    "        model: Transformer model with SPECTER2 adapter.\n",
    "        text_batch: List of input strings.\n",
    "    Returns:\n",
    "        np.array of normalized embeddings.\n",
    "     \"\"\"\n",
    "    inputs = tokenizer(\n",
    "        text_batch,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors=\"pt\",\n",
    "        return_token_type_ids=False,\n",
    "    )\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(**inputs)\n",
    "        embeddings = output.last_hidden_state[:, 0, :]\n",
    "        embeddings = torch.nn.functional.normalize(embeddings, p=2, dim=1)\n",
    "\n",
    "    return embeddings.cpu().numpy()\n",
    "\n",
    "def embedding_to_pgvector_str(vec):\n",
    "    \"\"\"From np.array to string '[v1,v2,...]' for column ::vector.\"\"\"\n",
    "    return \"[\" + \",\".join(str(float(x)) for x in vec.tolist()) + \"]\"\n",
    "\n",
    "# DB update functions\n",
    "def update_embedding(record_id, embedding):\n",
    "    vector_str = embedding_to_pgvector_str(embedding)\n",
    "    cur.execute(\n",
    "        \"\"\"\n",
    "        UPDATE research_item\n",
    "        SET embedding_specter2 = %s\n",
    "        WHERE id = %s\n",
    "        \"\"\",\n",
    "        (vector_str, record_id),\n",
    "    )\n",
    "\n",
    "def set_null_embedding(record_id):\n",
    "    cur.execute(\n",
    "        \"\"\"\n",
    "        UPDATE research_item\n",
    "        SET embedding_specter2 = NULL\n",
    "        WHERE id = %s\n",
    "        \"\"\",\n",
    "        (record_id,),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BwdqMGYDLFXJ"
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_item(item):\n",
    "    if isinstance(item, str):\n",
    "        item = json.loads(item)\n",
    "\n",
    "    title = (item.get(\"title\") or \"\").strip()\n",
    "    abstract = (item.get(\"abstract\") or \"\").strip()\n",
    "\n",
    "    if abstract:\n",
    "        text = f\"{title}. {abstract}\"\n",
    "    else:\n",
    "        text = title\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def search_specter2(query, top_k=5):\n",
    "    \n",
    "    # query embedding\n",
    "    q_emb = embed_input(doc_model, [query])[0]  # np.array (768,)\n",
    "    q_emb_str = embedding_to_pgvector_str(q_emb)\n",
    "\n",
    "    sql = \"\"\"\n",
    "    WITH q AS (\n",
    "        SELECT %s::vector AS emb\n",
    "    )\n",
    "    SELECT\n",
    "        ri.id,\n",
    "        ri.data,\n",
    "        ri.embedding_specter2 <=> q.emb AS distance\n",
    "    FROM research_item AS ri\n",
    "    JOIN research_item_type AS rit\n",
    "        ON ri.research_item_type_id = rit.id\n",
    "    JOIN q\n",
    "        ON TRUE\n",
    "    WHERE rit.type = 'publication'\n",
    "      AND ri.embedding_specter2 IS NOT NULL\n",
    "    ORDER BY ri.embedding_specter2 <=> q.emb\n",
    "    LIMIT %s;\n",
    "    \"\"\"\n",
    "\n",
    "    with conn.cursor() as cur:\n",
    "        # cur.execute(\"\"\"SET hnsw.ef_search = 1000;\"\"\")\n",
    "        cur.execute(sql, (q_emb_str, top_k))\n",
    "        rows = cur.fetchall()\n",
    "\n",
    "\n",
    "    print(f\"\\n=== Query: {query!r} ===\")\n",
    "    for i, (doc_id, data_json, distance) in enumerate(rows, start=1):\n",
    "        \n",
    "        score = 1.0 - float(distance)\n",
    "\n",
    "        text = clean_item(data_json)\n",
    "        preview = text[:200] + (\"...\" if len(text) > 200 else \"\")\n",
    "\n",
    "        print(f\"\\n[{i}] id={doc_id}  score={score:.3f}\")\n",
    "        print(f\"     text: {preview}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Query: 'contrastive learning for cross-domain video recognition' ===\n",
      "\n",
      "[1] id=7797  score=0.802\n",
      "     text: Dual-Head Contrastive Domain Adaptation for Video Action Recognition. Unsupervised domain adaptation (UDA) methods have become very popular in computer vision. However, while several techniques have b...\n",
      "\n",
      "[2] id=22748  score=0.796\n",
      "     text: Contrastive Learning for Cross-Domain Open World Recognition. The ability to evolve is fundamental for any valuable autonomous agent whose knowledge cannot remain limited to that injected by the manuf...\n",
      "\n",
      "[3] id=9855  score=0.784\n",
      "     text: Boosting binary masks for multi-domain learning through affine transformations. In this work, we present a new, algorithm for multi-domain learning. Given a pretrained architecture and a set of visual...\n",
      "\n",
      "[4] id=28484  score=0.780\n",
      "     text: MultiDIAL: Domain Alignment Layers for (Multisource) Unsupervised Domain Adaptation. One of the main challenges for developing visual recognition systems working in the wild is to devise computational...\n",
      "\n",
      "[5] id=31457  score=0.778\n",
      "     text: DA4Event: Towards Bridging the Sim-to-Real Gap for Event Cameras Using Domain Adaptation. © 2016 IEEE.Event cameras are novel bio-inspired sensors, which asynchronously capture pixel-level intensity c...\n",
      "\n",
      "[6] id=10112  score=0.777\n",
      "     text: Adversarial feature refinement for cross-view action recognition. Apparent motion information of an action may vary dramatically from one view to another, making transfer of knowledge across views a c...\n",
      "\n",
      "[7] id=24486  score=0.776\n",
      "     text: Adaptive Deep Learning through Visual Domain Localization\n",
      "\n",
      "[8] id=15639  score=0.776\n",
      "     text: Distance-based Hyperspherical Classification for Multi-source Open-Set Domain Adaptation. Vision systems trained in closed-world scenarios fail when presented with new environmental conditions, new da...\n",
      "\n",
      "[9] id=46401  score=0.775\n",
      "     text: Hallucinating agnostic images to generalize across domains. The ability to generalize across visual domains is crucial for the robustness of artificial recognition systems. Although many training sour...\n",
      "\n",
      "[10] id=36362  score=0.773\n",
      "     text: Generalizing to Unseen Domains via Adversarial Data Augmentation. We are concerned with learning models that generalize well to different unseen domains. We consider a worst-case formulation over data...\n",
      "\n",
      "[11] id=7550  score=0.773\n",
      "     text: Unsupervised Domain Adaptation for Video Transformers in Action Recognition. Over the last few years, Unsupervised Domain Adaptation (UDA) techniques have acquired remarkable importance and popularity...\n",
      "\n",
      "[12] id=46568  score=0.772\n",
      "     text: Towards Recognizing Unseen Categories in Unseen Domains. Current deep visual recognition systems suffer from severe performance degradation when they encounter new images from classes and scenarios un...\n",
      "\n",
      "[13] id=39373  score=0.772\n",
      "     text: Positive-unlabeled learning for open set domain adaptation. © 2020 Elsevier B.V.Open Set Domain Adaptation (OSDA) focuses on bridging the domain gap between a labeled source domain and an unlabeled ta...\n",
      "\n",
      "[14] id=23579  score=0.772\n",
      "     text: Generalizing to unseen domains via adversarial data augmentation. We are concerned with learning models that generalize well to different unseen domains. We consider a worst-case formulation over data...\n",
      "\n",
      "[15] id=31738  score=0.771\n",
      "     text: Adagraph: Unifying predictive and continuous domain adaptation through graphs. The ability to categorize is a cornerstone of visual intelligence, and a key functionality for artificial, autonomous vis...\n",
      "\n",
      "[16] id=3296  score=0.771\n",
      "     text: A testbed for cross-dataset analysis. Despite the increasing interest towards domain adaptation and transfer learning techniques to generalize over image collections and overcome their biases, the vis...\n",
      "\n",
      "[17] id=24483  score=0.770\n",
      "     text: Adaptive Deep Learning through Visual Domain Localization. A commercial robot, trained by its manufacturer to recognize a predefined number and type of objects, might be used in many settings, that wi...\n",
      "\n",
      "[18] id=22524  score=0.770\n",
      "     text: Adaptive Deep Learning Through Visual Domain Localization. A commercial robot, trained by its manufacturer to recognize a predefined number and type of objects, might be used in many settings, that wi...\n",
      "\n",
      "[19] id=20460  score=0.769\n",
      "     text: Learning the roots of visual domain shift. In this paper we focus on the spatial nature of visual domain shift, attempting to learn where domain adaptation originates in each given image of the source...\n",
      "\n",
      "[20] id=24194  score=0.768\n",
      "     text: Cross-view action recognition with small-scale datasets. Cross-view action recognition refers to the task of recognizing actions observed from view-points that are unfamiliar to the system. To address...\n",
      "\n",
      "[21] id=6669  score=0.767\n",
      "     text: Just DIAL: Domain alignment layers for unsupervised domain adaptation. The empirical fact that classifiers, trained on given data collections, perform poorly when tested on data acquired in different ...\n",
      "\n",
      "[22] id=38175  score=0.767\n",
      "     text: Bridging Continual Learning of Motion and Self-Supervised Representations. Efficiently learning unsupervised pixel-wise visual representations is crucial for training agents that can perceive their en...\n",
      "\n",
      "[23] id=25608  score=0.767\n",
      "     text: Boosting Domain Adaptation by Discovering Latent Domains. Current Domain Adaptation (DA) methods based on deep architectures assume that the source samples arise from a single distribution. However, i...\n",
      "\n",
      "[24] id=24460  score=0.766\n",
      "     text: Domain Generalization with Domain-Specific Aggregation Modules. Visual recognition systems are meant to work in the real world. For this to happen, they must work robustly in any visual domain, and no...\n",
      "\n",
      "[25] id=28419  score=0.765\n",
      "     text: Domain generalization by solving jigsaw puzzles. Human adaptability relies crucially on the ability to learn and merge knowledge both from supervised and unsupervised learning: The parents point out f...\n",
      "\n",
      "[26] id=37248  score=0.765\n",
      "     text: Domain Generalization by Solving Jigsaw Puzzles. Human adaptability relies crucially on the ability to\n",
      "learn and merge knowledge both from supervised and unsupervised learning: the parents point out f...\n",
      "\n",
      "[27] id=9883  score=0.765\n",
      "     text: Single view learning in action recognition. Viewpoint is an essential aspect of how an action is visually perceived, with the motion appearing substantially different for some viewpoint pairs. Data dr...\n",
      "\n",
      "[28] id=4898  score=0.764\n",
      "     text: On the Effectiveness of Image Rotation for Open Set Domain Adaptation. Open Set Domain Adaptation (OSDA) bridges the domain gap between a labeled source domain and an unlabeled target domain, while al...\n",
      "\n",
      "[29] id=41854  score=0.762\n",
      "     text: AutoDIAL: Automatic Domain Alignment Layers. Classifiers trained on given databases perform poorly when tested on data acquired in different settings. This is explained in domain adaptation through a ...\n",
      "\n",
      "[30] id=29259  score=0.762\n",
      "     text: LCMV: Lightweight Classification Module for Video Domain Adaptation. Video action recognition models exhibit high performance on in-distribution data but struggle with distribution shifts in test data...\n",
      "\n",
      "[31] id=49280  score=0.762\n",
      "     text: On the Challenges of Open World Recognition under Shifting Visual Domains. Robotic visual systems operating in the wild must act in unconstrained scenarios, under different environmental conditions wh...\n",
      "\n",
      "[32] id=3241  score=0.761\n",
      "     text: Continual Source-Free Unsupervised Domain Adaptation. Source-free Unsupervised Domain Adaptation (SUDA) approaches inherently exhibit catastrophic forgetting. Typically, models trained on a labeled so...\n",
      "\n",
      "[33] id=10147  score=0.761\n",
      "     text: Overview of the ImageCLEF 2014 Domain Adaptation Task. This paper describes the first edition of the Domain Adaptation Task at ImageCLEF 2014. Domain adaptation refers to the challenge of leveraging o...\n",
      "\n",
      "[34] id=22529  score=0.759\n",
      "     text: Adversarial Feature Augmentation for Unsupervised Domain Adaptation. Recent works showed that Generative Adversarial Networks (GANs) can be successfully applied in unsupervised domain adaptation, wher...\n",
      "\n",
      "[35] id=32339  score=0.759\n",
      "     text: Best sources forward: domain generalization through source-specific nets. A long standing problem in visual object categorization is\n",
      "the ability of algorithms to generalize across different testing\n",
      "co...\n",
      "\n",
      "[36] id=21658  score=0.759\n",
      "     text: Learning deep visual object models from noisy web data: How to make it work. Deep networks thrive when trained on large scale data collections. This has given ImageNet a central role in the developmen...\n",
      "\n",
      "[37] id=30841  score=0.759\n",
      "     text: Learning with Privileged Information via Adversarial Discriminative Modality Distillation. Heterogeneous data modalities can provide complementary cues for several tasks, usually leading to more robus...\n",
      "\n",
      "[38] id=25567  score=0.758\n",
      "     text: Best Sources Forward: Domain Generalization through Source-Specific Nets. A long standing problem in visual object categorization is the ability of algorithms to generalize across different testing co...\n",
      "\n",
      "[39] id=22057  score=0.758\n",
      "     text: Learning with privileged information via adversarial discriminative   modality distillation. Heterogeneous data modalities can provide complementary cues for several tasks, usually leading to more rob...\n",
      "\n",
      "[40] id=21836  score=0.758\n",
      "     text: Learning with privileged information via adversarial discriminative modality distillation. Heterogeneous data modalities can provide complementary cues for several tasks, usually leading to more robus...\n"
     ]
    }
   ],
   "source": [
    "test_queries = ['contrastive learning for cross-domain video recognition']\n",
    "\n",
    "for q in test_queries:\n",
    "    search_specter2(q, top_k=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myEnv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
