{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from adapters import AutoAdapterModel\n",
    "import torch.nn.functional as F\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AZoKXvr0KzEd"
   },
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_140341/1679224296.py:19: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    }
   ],
   "source": [
    "conn = psycopg2.connect(\n",
    "    dbname=\"scientilla\",\n",
    "    user=\"postgres\",\n",
    "    password=\"pwd\",\n",
    "    host=\"localhost\",\n",
    "    port=5444,\n",
    ")\n",
    "cur = conn.cursor()\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT ri.id, ri.data\n",
    "FROM research_item AS ri\n",
    "JOIN research_item_type AS rit\n",
    "    ON ri.research_item_type_id = rit.id\n",
    "WHERE rit.type IN ('publication', 'patent')\n",
    "ORDER BY ri.id;\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, conn)\n",
    "ids = df[\"id\"].tolist()\n",
    "data_array = df[\"data\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bt-n86dzK5YT"
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATTERN = re.compile(\n",
    "    r\"^(Editorial|Preface|Erratum|Corrigendum|Introduction|Foreword|Guest Editorial)( to)?:?\\s*\",\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "def clean_title(title: str) -> str:\n",
    "    t = (title or \"\").strip()\n",
    "    t = PATTERN.sub(\"\", t).strip()\n",
    "    return t\n",
    "\n",
    "def build_clean_text_and_flags(item, sep_token: str | None = None):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      - text (string for the embedding) or None if to be filtered out\n",
    "      - has_abstract (bool)\n",
    "      - title_word_count (int)\n",
    "    \"\"\"\n",
    "    title_raw = item.get(\"title\") or \"\"\n",
    "    abstract_raw = item.get(\"abstract\") or \"\"\n",
    "\n",
    "    title_clean = clean_title(title_raw)\n",
    "    title_clean = title_clean.strip()\n",
    "\n",
    "    title_words = title_clean.split()\n",
    "    title_word_count = len(title_words)\n",
    "\n",
    "    abstract_clean = (abstract_raw or \"\").strip()\n",
    "    has_abstract = bool(abstract_clean)\n",
    "\n",
    "    if title_word_count <= 3 and not has_abstract:\n",
    "        return None, has_abstract, title_word_count\n",
    "\n",
    "    if has_abstract:\n",
    "        if sep_token:\n",
    "            text = f\"{title_clean} {sep_token} {abstract_clean}\"\n",
    "        else:\n",
    "            text = f\"{title_clean}. {abstract_clean}\"\n",
    "    else:\n",
    "        text = f\"{title_clean}.\"\n",
    "\n",
    "    text = text.strip()\n",
    "    if not text:\n",
    "        return None, has_abstract, title_word_count\n",
    "\n",
    "    return text, has_abstract, title_word_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 4 files: 100%|██████████| 4/4 [00:00<00:00, 59283.45it/s]\n",
      "There are adapters available but none are activated for the forward pass.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stack[proximity]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertAdapterModel(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(31090, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttentionWithAdapters(\n",
       "              (query): LoRALinearTorch(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (shared_parameters): ModuleDict()\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (key): LoRALinearTorch(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (shared_parameters): ModuleDict()\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (value): LoRALinearTorch(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (shared_parameters): ModuleDict()\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (prefix_tuning): PrefixTuningLayer(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (output): BertSelfOutputWithAdapters(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): LoRALinearTorch(\n",
       "              in_features=768, out_features=3072, bias=True\n",
       "              (shared_parameters): ModuleDict()\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutputWithAdapters(\n",
       "            (dense): LoRALinearTorch(\n",
       "              in_features=3072, out_features=768, bias=True\n",
       "              (shared_parameters): ModuleDict()\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (adapters): ModuleDict(\n",
       "              (proximity): Adapter(\n",
       "                (non_linearity): Activation_Function_Class(\n",
       "                  (f): ReLU()\n",
       "                )\n",
       "                (adapter_down): Sequential(\n",
       "                  (0): Linear(in_features=768, out_features=48, bias=True)\n",
       "                  (1): Activation_Function_Class(\n",
       "                    (f): ReLU()\n",
       "                  )\n",
       "                )\n",
       "                (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "          (reft_layer): ReftLayer(\n",
       "            (refts): ModuleDict()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "    (invertible_adapters): ModuleDict()\n",
       "    (shared_parameters): ModuleDict()\n",
       "    (prefix_tuning): PrefixTuningPool(\n",
       "      (prefix_tunings): ModuleDict()\n",
       "    )\n",
       "    (prompt_tuning): PromptTuningLayer(\n",
       "      (base_model_embeddings): Embedding(31090, 768, padding_idx=0)\n",
       "      (prompt_tunings): ModuleDict()\n",
       "    )\n",
       "  )\n",
       "  (heads): ModuleDict()\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/specter2_base\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "doc_model = AutoAdapterModel.from_pretrained(\"allenai/specter2_base\")\n",
    "\n",
    "adapter_name = doc_model.load_adapter(\n",
    "    \"allenai/specter2\",\n",
    "    source=\"hf\",\n",
    "    load_as=\"proximity\",\n",
    "    set_active=True,\n",
    ")\n",
    "print(doc_model.active_adapters)\n",
    "\n",
    "doc_model.to(device)\n",
    "doc_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of docs before filtering: 52968\n",
      "Number of docs after filtering (with embeddings): 52536\n",
      "Number of docs set to NULL embedding: 432\n"
     ]
    }
   ],
   "source": [
    "cleaned_texts = []\n",
    "filtered_ids = []\n",
    "has_abstract_flags = []\n",
    "title_word_counts = []\n",
    "bad_ids = []\n",
    "\n",
    "for doc_id, item in zip(ids, data_array):\n",
    "    text, has_abs, twc = build_clean_text_and_flags(\n",
    "        item,\n",
    "        sep_token=tokenizer.sep_token\n",
    "    )\n",
    "    if text is None:\n",
    "        bad_ids.append(doc_id)\n",
    "        continue\n",
    "\n",
    "    cleaned_texts.append(text)\n",
    "    filtered_ids.append(doc_id)\n",
    "    has_abstract_flags.append(has_abs)\n",
    "    title_word_counts.append(twc)\n",
    "\n",
    "print(f\"Number of docs before filtering: {len(ids)}\")\n",
    "print(f\"Number of docs after filtering (with embeddings): {len(filtered_ids)}\")\n",
    "print(f\"Number of docs set to NULL embedding: {len(bad_ids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qgQWhNs8K_J5"
   },
   "source": [
    "## Dataset Embedding Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_input(model, text_batch):\n",
    "    \"\"\"Calculate the embeddings for a batch of texts.\n",
    "    Args:\n",
    "        model: Transformer model with SPECTER2 adapter.\n",
    "        text_batch: List of input strings.\n",
    "    Returns:\n",
    "        np.array of normalized embeddings.\n",
    "     \"\"\"\n",
    "    inputs = tokenizer(\n",
    "        text_batch,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors=\"pt\",\n",
    "        return_token_type_ids=False,\n",
    "    )\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(**inputs)\n",
    "        embeddings = output.last_hidden_state[:, 0, :]\n",
    "        embeddings = torch.nn.functional.normalize(embeddings, p=2, dim=1)\n",
    "\n",
    "    return embeddings.cpu().numpy()\n",
    "\n",
    "def embedding_to_pgvector_str(vec):\n",
    "    \"\"\"From np.array to string '[v1,v2,...]' for column ::vector.\"\"\"\n",
    "    return \"[\" + \",\".join(str(float(x)) for x in vec.tolist()) + \"]\"\n",
    "\n",
    "def update_embedding(record_id, embedding):\n",
    "    vector_str = embedding_to_pgvector_str(embedding)\n",
    "    cur.execute(\n",
    "        \"\"\"\n",
    "        UPDATE research_item\n",
    "        SET embedding_specter2 = %s\n",
    "        WHERE id = %s\n",
    "        \"\"\",\n",
    "        (vector_str, record_id),\n",
    "    )\n",
    "\n",
    "def set_null_embedding(record_id):\n",
    "    cur.execute(\n",
    "        \"\"\"\n",
    "        UPDATE research_item\n",
    "        SET embedding_specter2 = NULL\n",
    "        WHERE id = %s\n",
    "        \"\"\",\n",
    "        (record_id,),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeds = []\n",
    "batch_size = 16\n",
    "\n",
    "for i in range(0, len(cleaned_texts), batch_size):\n",
    "    batch_texts = cleaned_texts[i : i + batch_size]\n",
    "    batch_embeds = embed_input(doc_model, batch_texts)\n",
    "    all_embeds.append(batch_embeds)\n",
    "\n",
    "if all_embeds:\n",
    "    embeds = np.vstack(all_embeds)\n",
    "else:\n",
    "    embeds = np.zeros((0, 768), dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save to db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rec_id, vector in zip(filtered_ids, embeds):\n",
    "    update_embedding(record_id=rec_id, embedding=vector)\n",
    "\n",
    "for rec_id in bad_ids:\n",
    "    set_null_embedding(rec_id)\n",
    "\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BwdqMGYDLFXJ"
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 4 files: 100%|██████████| 4/4 [00:00<00:00, 81442.80it/s]\n",
      "There are adapters available but none are activated for the forward pass.\n"
     ]
    }
   ],
   "source": [
    "conn = psycopg2.connect(\n",
    "    dbname=\"scientilla\",\n",
    "    user=\"postgres\",\n",
    "    password=\"pwd\",\n",
    "    host=\"localhost\",\n",
    "    port=5444,\n",
    ")\n",
    "cur = conn.cursor()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/specter2_base\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "doc_model = AutoAdapterModel.from_pretrained(\"allenai/specter2_base\")\n",
    "\n",
    "doc_model.load_adapter(\n",
    "    \"allenai/specter2_adhoc_query\",\n",
    "    source=\"hf\",\n",
    "    load_as=\"query\",\n",
    "    set_active=True,\n",
    ")\n",
    "\n",
    "\n",
    "def embedding_to_pgvector_str(vec):\n",
    "    \"\"\"From np.array to string '[v1,v2,...]' for ::vector.\"\"\"\n",
    "    return \"[\" + \",\".join(str(float(x)) for x in vec.tolist()) + \"]\"\n",
    "\n",
    "\n",
    "def clean_item(item):\n",
    "    if isinstance(item, str):\n",
    "        item = json.loads(item)\n",
    "\n",
    "    title = (item.get(\"title\") or \"\").strip()\n",
    "    abstract = (item.get(\"abstract\") or \"\").strip()\n",
    "\n",
    "    if abstract:\n",
    "        text = f\"{title}. {abstract}\"\n",
    "    else:\n",
    "        text = title\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def search_specter2(query, top_k=5):\n",
    "    \n",
    "    # query embedding\n",
    "    q_emb = embed_input(doc_model, [query])[0]  # np.array (768,)\n",
    "    q_emb_str = embedding_to_pgvector_str(q_emb)\n",
    "\n",
    "    sql = \"\"\"\n",
    "    WITH q AS (\n",
    "        SELECT %s::vector AS emb\n",
    "    )\n",
    "    SELECT\n",
    "        ri.id,\n",
    "        ri.data,\n",
    "        ri.embedding_specter2 <=> q.emb AS distance\n",
    "    FROM research_item AS ri\n",
    "    JOIN research_item_type AS rit\n",
    "        ON ri.research_item_type_id = rit.id\n",
    "    JOIN q\n",
    "        ON TRUE\n",
    "    WHERE rit.type = 'publication'\n",
    "      AND ri.embedding_specter2 IS NOT NULL\n",
    "    ORDER BY ri.embedding_specter2 <=> q.emb\n",
    "    LIMIT %s;\n",
    "    \"\"\"\n",
    "\n",
    "    with conn.cursor() as cur:\n",
    "        # cur.execute(\"\"\"SET hnsw.ef_search = 100;\"\"\")\n",
    "        cur.execute(sql, (q_emb_str, top_k))\n",
    "        rows = cur.fetchall()\n",
    "\n",
    "\n",
    "    print(f\"\\n=== Query: {query!r} ===\")\n",
    "    for i, (doc_id, data_json, distance) in enumerate(rows, start=1):\n",
    "        \n",
    "        score = 1.0 - float(distance)\n",
    "\n",
    "        text = clean_item(data_json)\n",
    "        preview = text[:200] + (\"...\" if len(text) > 200 else \"\")\n",
    "\n",
    "        print(f\"\\n[{i}] id={doc_id}  score={score:.3f}\")\n",
    "        print(f\"     text: {preview}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Query: 'Multiphoton Microscopy Advances Toward Super Resolution' ===\n",
      "\n",
      "[1] id=2148  score=0.864\n",
      "     text: Multiphoton Microscopy Advances Toward Super Resolution\n",
      "\n",
      "[2] id=17490  score=0.825\n",
      "     text: The development of microscopy for super-resolution: Confocal microscopy, and image scanning microscopy. Optical methods of super-resolution microscopy, such as confocal microscopy, structured illumina...\n",
      "\n",
      "[3] id=36633  score=0.815\n",
      "     text: Near infrared super-resolution microscopy.\n",
      "\n",
      "[4] id=27261  score=0.815\n",
      "     text: Super-resolution fluorescence microscopy. Super resolution microscopy circumvents what seemed to be a fundamental limit in optical microscopy. Today we can say that optical microscopy is todaly, in pr...\n",
      "\n",
      "[5] id=4626  score=0.801\n",
      "     text: The 2015 super-resolution microscopy roadmap. Far-field optical microscopy using focused light is an important tool in a number of scientific disciplines including chemical, (bio)physical and biomedic...\n",
      "\n",
      "=== Query: 'renewable energies' ===\n",
      "\n",
      "[1] id=39539  score=0.848\n",
      "     text: Renewable Energy, Photovoltaic System and Solar Power Plant\n",
      "\n",
      "[2] id=25192  score=0.835\n",
      "     text: Electrochemical Reduction of CO2 With Good Efficiency on a Nanostructured Cu-Al Catalyst. Copyright © 2022 Zeng, Castellino, Fontana, Sacco, Monti, Chiodoni and Pirri.Carbon monoxide (CO) and formic a...\n",
      "\n",
      "[3] id=30793  score=0.833\n",
      "     text: An electrochemical platform for the carbon dioxide capture and conversion to syngas. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.We report on a simple electrochemical system able to captu...\n",
      "\n",
      "[4] id=49018  score=0.833\n",
      "     text: An electrochemical platform for the carbon dioxide capture and conversion to syngas. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.We report on a simple electrochemical system able to captu...\n",
      "\n",
      "[5] id=33841  score=0.831\n",
      "     text: Solar steam generation on scalable ultrathin thermoplasmonic TiN nanocavity arrays. © 2021 Elsevier LtdPlasmonic-based solar absorbers exhibit complete light absorption in a sub-µm thickness, represen...\n",
      "\n",
      "=== Query: 'heart' ===\n",
      "\n",
      "[1] id=39750  score=0.786\n",
      "     text: A longitudinal study of interoception changes in the times of COVID-19: Effects on psychophysiological health and well-being. Background: Interoception – the processing of the internal state of the bo...\n",
      "\n",
      "[2] id=26423  score=0.786\n",
      "     text: A longitudinal study of interoception changes in the times of COVID-19: Effects on psychophysiological health and well-being. Background: Interoception – the processing of the internal state of the bo...\n",
      "\n",
      "[3] id=15015  score=0.772\n",
      "     text: Pre-pandemic autonomic nervous system activity predicts mood regulation expectancies during COVID-19 in Israel. Despite the unfolding impact of the COVID-19 pandemic on psychological well-being, there...\n",
      "\n",
      "[4] id=5790  score=0.772\n",
      "     text: The “embreathment” illusion highlights the role of breathing in corporeal awareness. © 2020 American Physiological Society. All rights reserved.Recent theories posit that physiological signals contrib...\n",
      "\n",
      "[5] id=15645  score=0.768\n",
      "     text: Revisiting Abnormalities of Ventricular Depolarization: Redefining Phenotypes and Associated Outcomes Using Tree-Based Dimensionality Reduction. BACKGROUND: Abnormal ventricular depolarization, eviden...\n",
      "\n",
      "=== Query: 'cardiology' ===\n",
      "\n",
      "[1] id=51735  score=0.795\n",
      "     text: In Silico Modeling of Coronavirus Disease 2019 Acute Respiratory Distress Syndrome: Pathophysiologic Insights and Potential Management Implications. Objectives: Patients with coronavirus disease 2019 ...\n",
      "\n",
      "[2] id=26423  score=0.791\n",
      "     text: A longitudinal study of interoception changes in the times of COVID-19: Effects on psychophysiological health and well-being. Background: Interoception – the processing of the internal state of the bo...\n",
      "\n",
      "[3] id=39750  score=0.791\n",
      "     text: A longitudinal study of interoception changes in the times of COVID-19: Effects on psychophysiological health and well-being. Background: Interoception – the processing of the internal state of the bo...\n",
      "\n",
      "[4] id=8914  score=0.788\n",
      "     text: Correction: Mitigating losses: how scientific organisations can help address the impact of the COVID-19 pandemic on early-career researchers. © 2020 The Author(s). Published with license by Taylor & F...\n",
      "\n",
      "[5] id=51945  score=0.782\n",
      "     text: AIforCOVID: Predicting the clinical outcomes in patients with COVID-19 applying AI to chest-X-rays. An Italian multicentre study. Recent epidemiological data report that worldwide more than 53 million...\n",
      "\n",
      "=== Query: 'nature' ===\n",
      "\n",
      "[1] id=52568  score=0.789\n",
      "     text: Using Nanocompore to Identify RNA Modifications from Direct RNA Nanopore Sequencing Data. RNA modifications can alter the behavior of RNA molecules depending on where they are located on the strands. ...\n",
      "\n",
      "[2] id=48784  score=0.785\n",
      "     text: Author Correction: Discovery of widespread transcription initiation at microsatellites predictable by sequence-based deep neural network (Nature Communications, (2021), 12, 1, (3297), 10.1038/s41467-0...\n",
      "\n",
      "[3] id=40752  score=0.785\n",
      "     text: Discovery of widespread transcription initiation at microsatellites predictable by sequence-based deep neural network. © 2021, The Author(s).Using the Cap Analysis of Gene Expression (CAGE) technology...\n",
      "\n",
      "[4] id=8805  score=0.783\n",
      "     text: Zero Sales Resistance: The Dark Side of Big Data and Artificial Intelligence. Big data (BD) is the hue and cry of modern science and society. The impact of such data deluge is huge and far reaching fo...\n",
      "\n",
      "[5] id=28137  score=0.782\n",
      "     text: Deep learning path-like collective variable for enhanced sampling molecular dynamics. Several enhanced sampling techniques rely on the definition of collective variables to effectively explore free en...\n",
      "\n",
      "=== Query: 'biology' ===\n",
      "\n",
      "[1] id=46879  score=0.821\n",
      "     text: Sailing the Ocean of Complexity: Lessons from the Physics-Biology Interface. We live in a world of utmost complexity, outside and within us. There are thousands of billions of billions stars out there...\n",
      "\n",
      "[2] id=15373  score=0.815\n",
      "     text: Computational Systems Biology: Inference and Modeling. Computational Systems Biology: Inference and Modelling provides an introduction to, and overview of, network analysis inference approaches which ...\n",
      "\n",
      "[3] id=10397  score=0.814\n",
      "     text: Erratum: Applied Biological Sciences, Biophysics and Computational Biology ((Proc. Natl. Acad. Sci. U.S.A. (2021 ) 118 (e2107535118) DOI: 10.1073/pnas.2107535118). Correction for “Nanoconfinement of m...\n",
      "\n",
      "[4] id=30926  score=0.809\n",
      "     text: A Bayesian approach to reveal the key role of mask wearing in modulating projected interpersonal distance during the first COVID-19 outbreak. © 2021 Lisi et al. This is an open access article distribu...\n",
      "\n",
      "[5] id=8914  score=0.807\n",
      "     text: Correction: Mitigating losses: how scientific organisations can help address the impact of the COVID-19 pandemic on early-career researchers. © 2020 The Author(s). Published with license by Taylor & F...\n"
     ]
    }
   ],
   "source": [
    "test_queries = ['Multiphoton Microscopy Advances Toward Super Resolution','renewable energies','heart', 'cardiology', 'nature','biology']\n",
    "\n",
    "for q in test_queries:\n",
    "    search_specter2(q, top_k=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myEnv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
